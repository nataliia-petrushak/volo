{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup\n",
    "\n",
    "Create the clients and the policy for working with buckets.\n",
    "\n",
    "Prerequisites: the S3 bucket with raw data and the IAM Role with the Policy created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_SERVER_PUBLIC_KEY = input(\"AWS_SERVER_PUBLIC_KEY: \")\n",
    "AWS_SERVER_SECRET_KEY = input(\"AWS_SERVER_SECRET_KEY: \")\n",
    "AWS_SESSION_TOKEN = input(\"AWS_SESSION_TOKEN: \")\n",
    "REGION_NAME = input(\"REGION_NAME: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=AWS_SERVER_PUBLIC_KEY,\n",
    "    aws_secret_access_key=AWS_SERVER_SECRET_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN,\n",
    "    region_name=REGION_NAME\n",
    ")\n",
    "\n",
    "raw_bucket_name = \"existing-bucket-name\"  # Replace with the actual name\n",
    "formatted_bucket_name = \"existing-bucket-name\"  # Replace with the actual name\n",
    "role_name = \"existing-role-name\"  # Replace with the actual name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE in case I need to create the policy myself:\n",
    "\n",
    "# iam = boto3.client(\n",
    "#     \"iam\",\n",
    "#     aws_access_key_id=AWS_SERVER_PUBLIC_KEY,\n",
    "#     aws_secret_access_key=AWS_SERVER_SECRET_KEY,\n",
    "#     aws_session_token=AWS_SESSION_TOKEN,\n",
    "#     region_name=REGION_NAME\n",
    "# )\n",
    "\n",
    "# policy_arn = iam.create_policy(\n",
    "#     PolicyName=\"Bedrock-Finetuning-Role-Policy\",\n",
    "#     PolicyDocument=json.dumps({\n",
    "#         \"Version\": \"2012-10-17\",\n",
    "#         \"Statement\": [\n",
    "#             {\n",
    "#                 \"Effect\": \"Allow\",\n",
    "#                 \"Action\": [\n",
    "#                     \"s3:GetObject\",\n",
    "#                     \"s3:PutObject\",\n",
    "#                     \"s3:ListBucket\"\n",
    "#                 ],\n",
    "#                 \"Resource\": [\n",
    "#                     f\"arn:aws:s3:::{raw_bucket_name}\",\n",
    "#                     f\"arn:aws:s3:::{raw_bucket_name}/*\",\n",
    "#                     f\"arn:aws:s3:::{formatted_bucket_name}\",\n",
    "#                     f\"arn:aws:s3:::{formatted_bucket_name}/*\"\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "#     })\n",
    "# )['Policy']['Arn']\n",
    "\n",
    "# iam.attach_role_policy(\n",
    "#     RoleName=role_name,\n",
    "#     PolicyArn=policy_arn\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation\n",
    "\n",
    "Download the raw data from S3, format it for the LLM, and save back to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_s3(s3_bucket, s3_key, local_filename):\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    s3.download_file(s3_bucket, s3_key, f\"{dataset_dir}/{local_filename}\")\n",
    "    print(f\"Downloaded {s3_key} from {s3_bucket} to {dataset_dir}/{local_filename}\")\n",
    "\n",
    "# will modify later for the final raw data format\n",
    "def load_dataset_from_file(local_filename):\n",
    "    data = []\n",
    "    file_path = f\"{dataset_dir}/{local_filename}\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "# the data formatting for LLaMa 3. will modify later for the final raw data format\n",
    "def format_data(item: list[dict[str, str]]):\n",
    "    formatted_data = \"\"\n",
    "    for replic in item:\n",
    "        formatted_data += \"<|start_header_id|>\" + replic[\"role\"] + \"<|end_header_id|>\" + replic[\"content\"]\n",
    "    formatted_data = \"<|begin_of_text|>\" + formatted_data + \"<|eot_id|>\" + \"<|end_of_text|>\"\n",
    "    return formatted_data\n",
    "\n",
    "def save_formatted_data(local_filename, formatted_dataset):\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    with open(f\"{dataset_dir}/{local_filename}\", \"w\") as f:\n",
    "        for item in formatted_dataset:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "def upload_to_s3(local_filename, s3_bucket, s3_key):\n",
    "    full_path = f\"{dataset_dir}/{local_filename}\"\n",
    "    s3.upload_file(full_path, s3_bucket, s3_key)\n",
    "    print(f\"Uploaded {local_filename} to {s3_bucket}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_s3_key = \"your-input-key.jsonl\"  # Replace with the actual key\n",
    "download_from_s3(raw_bucket_name, input_s3_key, \"raw_data.jsonl\")  # Replace with the actual name\n",
    "dataset = load_dataset_from_file(\"raw_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_dataset = [format_data(item) for item in dataset]\n",
    "save_formatted_data(\"formatted_data.jsonl\", formatted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_s3_key = \"formatted_data.jsonl\"  # Replace with the actual key\n",
    "upload_to_s3(\"formatted_data.jsonl\", formatted_bucket_name, output_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client(\n",
    "    'bedrock',\n",
    "    aws_access_key_id=AWS_SERVER_PUBLIC_KEY,\n",
    "    aws_secret_access_key=AWS_SERVER_SECRET_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN,\n",
    "    region_name=REGION_NAME\n",
    ")\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "    \n",
    "customModelName = \"meta.llama3-8b-instruct-v1:0-therapist\"\n",
    "baseModelIdentifier = \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0\"\n",
    "\n",
    "datetime_string = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ft = bedrock.create_model_customization_job(\n",
    "    jobName=f\"Finetune-Job-{datetime_string}\",\n",
    "    customizationType=\"FINE_TUNING\",\n",
    "    roleArn=f\"arn:aws:iam::{account_id}:role/Bedrock-Finetuning-Role-{account_id}\",\n",
    "    hyperParameters = {\n",
    "        \"epochCount\": \"5\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \".0001\",\n",
    "        # \"learningRateWarmupSteps\": \"5\"\n",
    "    },\n",
    "    trainingDataConfig={\"s3Uri\": f\"s3://bedrock-finetuning-{account_id}/train.jsonl\"},\n",
    "    outputDataConfig={\"s3Uri\": f\"s3://bedrock-finetuning-{account_id}/finetuning-output\"},\n",
    "    customModelName=customModelName,\n",
    "    baseModelIdentifier=baseModelIdentifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobArn = response_ft.get('jobArn')\n",
    "print(jobArn)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
